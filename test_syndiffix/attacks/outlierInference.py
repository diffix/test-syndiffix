import json
import os
import time
import tempfile
import csv
import subprocess
import fire
import pandas as pd
import numpy as np
from sdv.tabular import TVAE, CTGAN


class OutlierInference(object):
    """
    Utility CLI to attack random-generated data using the "5.20 Detect outlier bucket" attack
    from https://arxiv.org/pdf/2201.04351.pdf.

    Currently the attack is compared on 4 kinds of data (`method` parameter):
      - `original` - do not synthesize anything, use original data to attack
      - `syndiffix`
      - `tvae`
      - `ctGan`
    """

    def one(self,
            syndiffixPath,
            nCategories,
            nAids,
            i,
            outlierCount,
            localOutlier):
        """
        Run one instance of the attack with all methods.

          - `syndiffixPath` - path to the SynDiffix project for dotnet to build and run
          - `nCategories` - list of integer of the possible counts of categories to generate data with.
                            Format like [2,5,10], without spaces
          - `nAids` - count of AIDs to generate data for.
          - `i` - index number of the dataset to run.
          - `outlierCount` - the count of rows for the outlier AID to have in the dataset (regular AIDs have 5-10 rows).
          - `localOutlier` - whether or not the outlier should be global or local for one category.

        Outputs the result in `.json` to a file under `data/`.
        """
        os.makedirs('data', exist_ok=True)
        attackResults = []
        for nCategories in nCategories:
            for method in ['original', 'syndiffix', 'tvae', 'ctGan']:
                result = runOneAttack(syndiffixPath,
                                      method,
                                      nCategories,
                                      nAids,
                                      i,
                                      outlierCount,
                                      localOutlier)
                attackResults.append(result)
        fileCode = f'{i:03d}'
        with open(f'data/result.{fileCode}.json', 'w+') as file:
            json.dump(attackResults, file)

    def collect(self, nDatasets=100):
        """
        Collect `.json` results generated by running `one` command(s) and aggregate results.
        """
        attackResults = []

        for i in range(nDatasets):
            fileCode = f'{i:03d}'
            with open(f'data/result.{fileCode}.json') as file:
                result = json.load(file)

            attackResults.extend(result)

        attackResults = pd.DataFrame(attackResults).groupby(['nCategories', 'method'])[
            'guessCorrect', 'elapsedSeconds'].mean().reset_index()
        print(attackResults.round(3).to_string())

    def csv(self,
            nCategories=[2, 5, 10],
            nAids=100,
            nDatasets=100,
            outlierCount=200,
            localOutlier=False):
        """
        Generate CSVs intended to be loaded to mostly.ai.
        """
        os.makedirs('data', exist_ok=True)
        for nCategories in nCategories:
            for i in range(nDatasets):
                np.random.seed(int(str(nCategories) + str(i)))
                aids = generateAids(nCategories, nAids, outlierCount, localOutlier)
                dataset = generateDataset(aids)
                aids = aids.drop(['count'], axis=1)
                dataset = dataset.drop(['count'], axis=1)
                fileCode = f'{nCategories:03d}.{i:03d}'
                with open(f'data/aids.{fileCode}.csv', 'w') as aidsFile, open(f'data/dataset{fileCode}.csv', 'w') as datasetFile:
                    _csvwrite(aids, aidsFile)
                    _csvwrite(dataset, datasetFile)

    def many(self,
             syndiffixPath,
             nCategories=[2, 5, 10],
             nAids=100,
             nDatasets=100,
             outlierCount=200,
             localOutlier=False):
        """
        Run multiple instances of attack in one process. See `one` for documentation on the arguments.

        NOTE: Only `syndiffix` and `original` are used as methods, since `tvae` and `ctGan` are time-consuming and 
              should be run via `one` as an array of jobs.
        """
        attackResults = []

        for nCategories in nCategories:
            for i in range(nDatasets):
                for method in ['original', 'syndiffix']:
                    result = runOneAttack(syndiffixPath, method, nCategories, nAids, i, outlierCount, localOutlier)
                    attackResults.append(result)

        attackResults = pd.DataFrame(attackResults).groupby(['nCategories', 'method'])[
            'guessCorrect', 'elapsedSeconds'].mean().reset_index()
        print(attackResults.round(3).to_string())


def _csvread(csvfile):
    # TODO: copied from csvUtils.py (x2). Is there a way we can avoid copying?
    return pd.read_csv(csvfile, index_col=False, sep=',', quotechar='\'', quoting=csv.QUOTE_MINIMAL)


def _csvwrite(rows, csvfile):
    return rows.to_csv(csvfile, index=False, sep=',', quotechar='\'', quoting=csv.QUOTE_MINIMAL,
                       header=True)


def runSynDiffix(syndiffixPath, columns, syndiffixArgs=[]):
    def synthesizer(data):
        # NOTE use of temp input files causes SynDiffix to be non-deterministic.
        with tempfile.NamedTemporaryFile() as inFile, tempfile.NamedTemporaryFile() as outFile:
            _csvwrite(data, inFile)
            syndiffix = subprocess.run(
                ['dotnet', 'run', '--configuration', 'Release', '--project',
                 syndiffixPath, inFile.name, '--aidcolumns', 'aid', '--columns', *columns, *syndiffixArgs],
                stdout=outFile,
                stderr=subprocess.PIPE,
            )
            errors = syndiffix.stderr.decode("utf-8").strip()
            if errors:
                print(errors)

            outCsv = _csvread(outFile.name)

        if syndiffix.returncode == 0:
            return outCsv
        else:
            raise f"SynDiffix exited with: {syndiffix.returncode}"

    return synthesizer


def modelSample(model, num_rows):
    with tempfile.NamedTemporaryFile() as file:
        # 1) removing the temp file, because model.sample expects it not to exist
        # 2) need to specify output_file_path as workaround for:
        #    https://github.com/sdv-dev/SDV/issues/1310
        os.remove(file.name)
        return model.sample(num_rows=num_rows, output_file_path=file.name)


def runTVAE(data):
    data = data.drop(['aid', 'count'], axis=1)

    model = TVAE()
    model.fit(data)
    return modelSample(model, data.shape[0])


def runCTGAN(data):
    data = data.drop(['aid', 'count'], axis=1)

    model = CTGAN()
    model.fit(data)
    return modelSample(model, num_rows=data.shape[0])


def generateAids(nCategories, nAids, outlierCount, localOutlier=False):
    aids = list(range(0, nAids))
    categories = pd.Series(np.random.randint(0, nCategories, size=nAids))

    # Fix outlier (first AID in the table) to have category 0.
    categories[0] = 0
    rowCounts = np.random.randint(5, 10, size=nAids)
    if localOutlier:
        # Outlier is local to the first group of categories, making the second group have higher row counts.
        secondGroup = categories >= nCategories // 2
        (secondGroupIdx, ) = np.where(secondGroup)
        rowCounts[secondGroupIdx] = np.random.randint(outlierCount, outlierCount * 3 // 2, size=len(secondGroupIdx))
    rowCounts[0] = outlierCount

    return pd.DataFrame({'aid': aids, 'cat': categories, 'count': rowCounts})


def generateDataset(uniqueDf):
    return uniqueDf.reindex(uniqueDf.index.repeat(uniqueDf['count'])).reset_index(drop=True)


def attack(synthAids, synthDataset, localOutlier, nCategories):
    if localOutlier:
        # The attacker knows the outlier is in the first group.
        synthAids = synthAids.iloc[np.where(synthAids['cat'] < nCategories // 2)]
        synthDataset = synthDataset.iloc[np.where(synthDataset['cat'] < nCategories // 2)]
    estAidsByCat = synthAids.groupby(['cat']).size().reset_index(name='count')
    estNAids = synthAids.size
    estNRows = synthDataset.size
    estRowsPerAid = estNRows / estNAids
    baselineRowsByCat = estAidsByCat.copy()
    baselineRowsByCat['count'] *= estRowsPerAid
    rowsByCat = synthDataset.groupby(['cat']).size().reset_index(name='count')

    # We need to take into account that some categories might have become low-count filtered.
    countsByCat = pd.merge(rowsByCat, baselineRowsByCat, how='inner', on='cat', suffixes=('Estimate', 'Baseline'))
    countsByCat['overBaseline'] = countsByCat['countEstimate'] - countsByCat['countBaseline']
    countsByCat = countsByCat.sort_values(by=['overBaseline'], ascending=False).reset_index(drop=True)

    if countsByCat['overBaseline'][0] > 0:
        guess = countsByCat['cat'][0]
    else:
        guess = None
    return guess


def runOneAttack(syndiffixPath,
                 method,
                 nCategories,
                 nAids,
                 i,
                 outlierCount,
                 localOutlier):
    print(method, " for ", nCategories, "categories. Dataset:", i)

    np.random.seed(int(str(nCategories) + str(i)))
    aids = generateAids(nCategories, nAids, outlierCount, localOutlier)
    dataset = generateDataset(aids)

    if method == 'syndiffix':
        synthesizer = runSynDiffix(syndiffixPath, ['cat:i'])
    elif method == 'original':
        def synthesizer(data): return data.copy()
    elif method == 'tvae':
        synthesizer = runTVAE
    elif method == 'ctGan':
        synthesizer = runCTGAN

    elapsed = None
    if method == 'mostly':
        fileCode = f'mostly.{nCategories:03d}.{i:03d}'
        with open(f'data/aids.{fileCode}.csv') as aidsFile, open(f'data/dataset{fileCode}.csv') as datasetFile:
            synthAids, synthDataset = _csvread(aidsFile), _csvread(datasetFile)
    else:
        start = time.time()
        synthAids, synthDataset = synthesizer(aids), synthesizer(dataset)
        elapsed = time.time() - start

    guess = attack(synthAids, synthDataset, localOutlier, nCategories)
    guessCorrect = guess == aids.loc[0, 'cat']

    return {
        'nCategories': nCategories,
        'guessCorrect': guessCorrect,
        'elapsedSeconds': elapsed,
        'method': method
    }


if __name__ == "__main__":
    fire.Fire(OutlierInference)
